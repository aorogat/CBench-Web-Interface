TL;DR: Two new tasks, training data released, new submission information!

QALD2017 CHALLENGE – ESWC 2017
ESWC 2017, May 28th, 2016 to June 1st, 2017 Portoroz, Slovenia.
https://project-hobbit.eu/challenges/qald2017/

The key challenge for Question Answering over Linked Data is to translate a user’s information need into a form such that it can be evaluated using standard Semantic Web query processing and inferencing techniques. The main task of QALD therefore is the following:

Given one or several RDF dataset(s) as well as additional knowledge sources and natural language questions or keywords, return the correct answers or a SPARQL query that retrieves these answers.
In order to focus on specific aspects and challenges, we propose the following three tasks:

Task 1: Multilingual question answering over DBpedia
Task 2: Hybrid question answering
Task 3: Large-Scale question answering over RDF
Task 4: Wikidata-based question answering

More details on the different tasks can be found here: https://project-hobbit.eu/challenges/qald2017/

Submission

The QALD challenge provides an automatic evaluation tool (GERBIL QA integrated into the HOBBIT platform) that is open source and available for everyone to re-use. This tool is accessible online, so that participants can simply upload the answers produced by their system or even check their system via a webservice. Each experiment will have a citable, time-stable and archivable URI which is both human- and machine-readable. It is mandatory for each system to provide an endpoint URL wrapped inside a provided Docker container after the submission in order to be evaluated with GERBIL QA.

We are accepting papers (up to 5 pages) describing the submitted approach and evaluation results. Submissions must be in English and in PDF, formatted in the style of the Springer Publications format for Lecture Notes in Computer Science (LNCS). 

Papers should be submitted through the EasyChair system (TBA) no later than midnight Friday March 10th, 2017, Hawaii Time. Submissions will be reviewed by members of the challenge program committee. Papers will be evaluated according to their significance, originality, technical content, style, clarity, and relevance to the challenge. The complete set of papers will be published with the CEUR Workshop Proceedings (CEUR-WS.org), listed by the DBLP.

For any questions, please write an email to Ricardo Usbeck (usbeck AT informatik.uni-leipzig.de).

Preliminary Schedule

Release of training data and instructions:	Friday January 13th, 2017
Release of test dataset:	Friday April 7th, 2017

Paper submission deadline:	Friday March 10th, 2017
Challenge paper reviews:	Tuesday April 5th, 2017
Paper Notifications and invitation to task:	Friday April 7th, 2017
Camera ready papers (5 pages document):	Sunday April 23rd, 2017
Submission of camera-ready papers:	April 24, 2014
